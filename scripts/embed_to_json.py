import json
import os
import hashlib
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv

load_dotenv()

# --- C·∫•u h√¨nh ---
RAW_FILE_PATH = os.getenv('PREPROCESSED_JSON_FILE', 'data/mock_products.json')
EMBED_FILE_PATH = os.getenv('EMBEDDED_JSON_FILE', 'data/mock_products_with_embedding.json')
MODEL_NAME = os.getenv('MODEL_NAME', 'sentence-transformers/all-MiniLM-L6-v2')
# ------------------

def _create_product_hash(product):
    keys_to_hash = ['id', 'name', 'description', 'category', 'price', 'image_url']
    content_string = "".join(str(product.get(key, '')) for key in keys_to_hash)
    return hashlib.md5(content_string.encode('utf-8')).hexdigest()

def load_json_data(file_path, encoding='utf-8-sig'):
    if not os.path.exists(file_path): return []
    try:
        with open(file_path, 'r', encoding=encoding) as f:
            return json.load(f)
    except json.JSONDecodeError:
        print(f"‚ö†Ô∏è C·∫£nh b√°o: File {file_path} l·ªói JSON. Coi nh∆∞ r·ªóng.")
        return []
    except Exception as e:
        print(f"‚ùå L·ªói ƒë·ªçc file {file_path}: {e}")
        return []

def load_model(model_name, device='cpu'):
    print(f"‚è≥ ƒêang t·∫£i m√¥ h√¨nh '{model_name}' v·ªÅ (ch·ªâ 1 l·∫ßn n·∫øu ch∆∞a c√≥)...")
    try:
        model = SentenceTransformer(model_name, device=device)
        print("‚úÖ T·∫£i m√¥ h√¨nh th√†nh c√¥ng.")
        return model
    except Exception as e:
        print(f"‚ùå L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng t·∫£i ƒë∆∞·ª£c m√¥ h√¨nh '{model_name}': {e}")
        return None

def main():
    print("\n--- B·∫Øt ƒë·∫ßu quy tr√¨nh t·∫°o Embedding ---")

    raw_products = load_json_data(RAW_FILE_PATH)
    if not raw_products:
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y ho·∫∑c kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file d·ªØ li·ªáu th√¥ '{RAW_FILE_PATH}'. D·ª´ng l·∫°i.")
        return

    cached_products = load_json_data(EMBED_FILE_PATH)
    cached_map = {p.get('id'): p for p in cached_products if p.get('id')}

    products_to_keep = []
    products_to_embed = []
    texts_to_embed = []
    stats = {"kept": 0, "updated": 0, "new": 0}
    processed_ids = set()

    print(f"üîç So s√°nh {len(raw_products)} s·∫£n ph·∫©m th√¥ v·ªõi {len(cached_map)} s·∫£n ph·∫©m ƒë√£ cache...")

    for product in tqdm(raw_products, desc="üîé So s√°nh d·ªØ li·ªáu"):
        product_id = product.get('id')
        if not product_id:
            print(f"‚ö†Ô∏è C·∫£nh b√°o: B·ªè qua s·∫£n ph·∫©m thi·∫øu ID: {product.get('name', 'Kh√¥ng t√™n')}")
            continue
        if product_id in processed_ids:
            print(f"‚ö†Ô∏è C·∫£nh b√°o: B·ªè qua ID s·∫£n ph·∫©m tr√πng l·∫∑p trong file th√¥: {product_id}")
            continue
        processed_ids.add(product_id)

        current_hash = _create_product_hash(product)
        cached_product = cached_map.get(product_id)

        if cached_product and cached_product.get('data_hash') == current_hash:
            products_to_keep.append(cached_product)
            stats["kept"] += 1
        else:
            product['data_hash'] = current_hash
            content = f"T√™n: {product.get('name','')}. M√¥ t·∫£: {product.get('description','')}. Danh m·ª•c: {product.get('category','')}"
            products_to_embed.append(product)
            texts_to_embed.append(content)
            stats["updated" if cached_product else "new"] += 1

    final_product_list = products_to_keep
    model = None

    if products_to_embed:
        print(f"\n‚è≥ Ph√°t hi·ªán {len(products_to_embed)} s·∫£n ph·∫©m c·∫ßn x·ª≠ l√Ω.")
        model = load_model(MODEL_NAME)
        if model is None:
            print("‚ùå Kh√¥ng th·ªÉ ti·∫øp t·ª•c v√¨ kh√¥ng t·∫£i ƒë∆∞·ª£c model.")
            return

        print(f"üß† B·∫Øt ƒë·∫ßu t·∫°o embedding...")
        try:
            embeddings = model.encode(texts_to_embed, show_progress_bar=True, device='cpu')
            print("‚úÖ T·∫°o embedding ho√†n t·∫•t.")

            for i, product in enumerate(products_to_embed):
                product['product_embedding'] = embeddings[i].tolist()
                final_product_list.append(product)
        except Exception as e:
            print(f"‚ùå L·ªói nghi√™m tr·ªçng khi t·∫°o embedding: {e}")
            # return # C√¢n nh·∫Øc d·ª´ng n·∫øu l·ªói
    else:
        print("\n‚úÖ Kh√¥ng c√≥ s·∫£n ph·∫©m n√†o c·∫ßn t·∫°o embedding m·ªõi.")

    final_product_list.sort(key=lambda p: p.get('id', ''))

    try:
        os.makedirs(os.path.dirname(EMBED_FILE_PATH), exist_ok=True)
        with open(EMBED_FILE_PATH, 'w', encoding='utf-8') as f:
            json.dump(final_product_list, f, indent=4, ensure_ascii=False)

        print(f"\n--- ‚úÖ HO√ÄN T·∫§T ---")
        print(f"üíæ ƒê√£ l∆∞u {len(final_product_list)} s·∫£n ph·∫©m v√†o '{EMBED_FILE_PATH}'")
        print(f"üìä Th·ªëng k√™: Gi·ªØ nguy√™n: {stats['kept']} | C·∫≠p nh·∫≠t: {stats['updated']} | M·ªõi: {stats['new']}")

    except Exception as e:
        print(f"‚ùå L·ªói nghi√™m tr·ªçng khi l∆∞u file '{EMBED_FILE_PATH}': {e}")

if __name__ == "__main__":
    main()